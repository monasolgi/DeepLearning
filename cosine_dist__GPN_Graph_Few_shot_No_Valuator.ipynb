{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cosine_dist_ GPN_Graph-Few-shot_No_Valuator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNP7vZJLfAPzIvsKg+NAutZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monasolgi/DeepLearning/blob/master/cosine_dist__GPN_Graph_Few_shot_No_Valuator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY_CXlfgYCxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2d5752-a931-4baa-8570-f5053b3ecb48"
      },
      "source": [
        "!wget 'https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_electronics_network.txt?raw=true'\n",
        "!wget 'https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_eletronics_test.mat?raw=true'\n",
        "!wget 'https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_eletronics_train.mat?raw=true'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-21 08:48:18--  https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_electronics_network.txt?raw=true\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_electronics_network.txt [following]\n",
            "--2021-06-21 08:48:18--  https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_electronics_network.txt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_electronics_network.txt [following]\n",
            "--2021-06-21 08:48:18--  https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_electronics_network.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1086626 (1.0M) [text/plain]\n",
            "Saving to: ‘Amazon_electronics_network.txt?raw=true.1’\n",
            "\n",
            "Amazon_electronics_ 100%[===================>]   1.04M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-06-21 08:48:18 (9.48 MB/s) - ‘Amazon_electronics_network.txt?raw=true.1’ saved [1086626/1086626]\n",
            "\n",
            "--2021-06-21 08:48:18--  https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_eletronics_test.mat?raw=true\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_eletronics_test.mat [following]\n",
            "--2021-06-21 08:48:18--  https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_eletronics_test.mat\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_eletronics_test.mat [following]\n",
            "--2021-06-21 08:48:19--  https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_eletronics_test.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4971904 (4.7M) [application/octet-stream]\n",
            "Saving to: ‘Amazon_eletronics_test.mat?raw=true.1’\n",
            "\n",
            "Amazon_eletronics_t 100%[===================>]   4.74M  16.3MB/s    in 0.3s    \n",
            "\n",
            "2021-06-21 08:48:20 (16.3 MB/s) - ‘Amazon_eletronics_test.mat?raw=true.1’ saved [4971904/4971904]\n",
            "\n",
            "--2021-06-21 08:48:20--  https://github.com/monasolgi/GPN_Graph-Few-shot/blob/master/few_shot_data/Amazon_eletronics_train.mat?raw=true\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_eletronics_train.mat [following]\n",
            "--2021-06-21 08:48:20--  https://github.com/monasolgi/GPN_Graph-Few-shot/raw/master/few_shot_data/Amazon_eletronics_train.mat\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_eletronics_train.mat [following]\n",
            "--2021-06-21 08:48:20--  https://raw.githubusercontent.com/monasolgi/GPN_Graph-Few-shot/master/few_shot_data/Amazon_eletronics_train.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16218608 (15M) [application/octet-stream]\n",
            "Saving to: ‘Amazon_eletronics_train.mat?raw=true.1’\n",
            "\n",
            "Amazon_eletronics_t 100%[===================>]  15.47M  26.2MB/s    in 0.6s    \n",
            "\n",
            "2021-06-21 08:48:21 (26.2 MB/s) - ‘Amazon_eletronics_train.mat?raw=true.1’ saved [16218608/16218608]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg1LgMkYVAb-"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import scipy.io as sio\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def load_data(dataset_source):\n",
        "    n1s = []\n",
        "    n2s = []\n",
        "    for line in open(\"/content/Amazon_electronics_network.txt?raw=true\"):\n",
        "        n1, n2 = line.strip().split('\\t')\n",
        "        n1s.append(int(n1))\n",
        "        n2s.append(int(n2))\n",
        "\n",
        "    num_nodes = max(max(n1s),max(n2s)) + 1\n",
        "    adj = sp.coo_matrix((np.ones(len(n1s)), (n1s, n2s)),\n",
        "                                 shape=(num_nodes, num_nodes))\n",
        "\n",
        "\n",
        "    data_train = sio.loadmat(\"/content/Amazon_eletronics_train.mat?raw=true\")\n",
        "    train_class = list(set(data_train[\"Label\"].reshape((1,len(data_train[\"Label\"])))[0]))\n",
        "    \n",
        "\n",
        "    data_test = sio.loadmat(\"/content/Amazon_eletronics_test.mat?raw=true\")\n",
        "    class_list_test = list(set(data_test[\"Label\"].reshape((1,len(data_test[\"Label\"])))[0]))\n",
        "\n",
        "\n",
        "    labels = np.zeros((num_nodes,1))\n",
        "    labels[data_train['Index']] = data_train[\"Label\"]\n",
        "    labels[data_test['Index']] = data_test[\"Label\"]\n",
        "\n",
        "    features = np.zeros((num_nodes,data_train[\"Attributes\"].shape[1]))\n",
        "    features[data_train['Index']] = data_train[\"Attributes\"].toarray()\n",
        "    features[data_test['Index']] = data_test[\"Attributes\"].toarray()\n",
        "\n",
        "    class_list = []\n",
        "    for cla in labels:\n",
        "        if cla[0] not in class_list:\n",
        "            class_list.append(cla[0])  # unsorted\n",
        "\n",
        "    id_by_class = {}\n",
        "    for i in class_list:\n",
        "        id_by_class[i] = []\n",
        "    for id, cla in enumerate(labels):\n",
        "        id_by_class[cla[0]].append(id)\n",
        "\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    labels = lb.fit_transform(labels)\n",
        "\n",
        "    degree = np.sum(adj, axis=1)\n",
        "    degree = torch.FloatTensor(degree)\n",
        "\n",
        "    adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "    features = torch.FloatTensor(features)\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "\n",
        "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "    \n",
        "    class_list_valid = random.sample(train_class, 36)\n",
        "\n",
        "    class_list_train = list(set(train_class).difference(set(class_list_valid)))\n",
        "\n",
        "    return adj, features, labels, degree, class_list_train, class_list_valid, class_list_test, id_by_class \n",
        "\n",
        "\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "\n",
        "def normalize_adj(adj):\n",
        "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    rowsum = np.array(adj.sum(1))\n",
        "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
        "\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "\n",
        "def f1(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    return f1\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "\n",
        "\n",
        "def task_generator(id_by_class, class_list, n_way, k_shot, m_query):\n",
        "\n",
        "    # sample class indices\n",
        "    class_selected = random.sample(class_list, n_way)\n",
        "    id_support = []\n",
        "    id_query = []\n",
        "    for cla in class_selected:\n",
        "        temp = random.sample(id_by_class[cla], k_shot + m_query)\n",
        "        id_support.extend(temp[:k_shot])\n",
        "        id_query.extend(temp[k_shot:])\n",
        "\n",
        "    return np.array(id_support), np.array(id_query), class_selected\n",
        "\n",
        "\n",
        "\n",
        "def euclidean_dist(x, y):\n",
        "    # x: N x D query\n",
        "    # y: M x D prototype\n",
        "    n = x.size(0)\n",
        "    m = y.size(0)\n",
        "    d = x.size(1)\n",
        "    assert d == y.size(1)\n",
        "\n",
        "    x = x.unsqueeze(1).expand(n, m, d)\n",
        "    y = y.unsqueeze(0).expand(n, m, d)\n",
        "\n",
        "    return torch.pow(x - y, 2).sum(2)  # N x M\n",
        "\n",
        "def cosine_dis(x,y):\n",
        "  z=y.transpose(1,0) \n",
        "\n",
        "  # cosine similarity between A and B\n",
        "  cos_sim=torch.matmul(x,z)/(torch.linalg.norm(x)*torch.linalg.norm(z))\n",
        "  cos_dis=1-cos_sim\n",
        " \n",
        "  return cos_dis"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwb2uCiuxc1h"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHTjJ5Dsxa1k"
      },
      "source": [
        "class GPN_Encoder(nn.Module):\n",
        "  def __init__(self, nfeat, nhid, dropout):\n",
        "    super(GPN_Encoder, self).__init__()\n",
        "\n",
        "    self.gc1 = GraphConvolution(nfeat, 2 * nhid)\n",
        "    self.gc2 = GraphConvolution(2 * nhid, nhid)\n",
        "    #self.fc3 = nn.Linear(nhid, 1)\n",
        "    self.dropout = dropout\n",
        "\n",
        "  def forward(self, x, adj):\n",
        "    x = torch.tanh(self.gc1(x, adj))\n",
        "    x = F.dropout(x, self.dropout, training=self.training)\n",
        "    x = F.relu(self.gc2(x, adj))\n",
        "    #x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMNDMpR-lqSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75794d3-f662-4a1c-dfe2-1dcbd28347f4"
      },
      "source": [
        "\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Training settings\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--use_cuda', action='store_true', help='Disables CUDA training.')\n",
        "parser.add_argument('--seed', type=int, default=1234, help='Random seed.')\n",
        "parser.add_argument('--episodes', type=int, default=200,\n",
        "                    help='Number of episodes to train.')\n",
        "parser.add_argument('--lr', type=float, default=0.005,\n",
        "                    help='Initial learning rate.')\n",
        "parser.add_argument('--weight_decay', type=float, default=5e-4,\n",
        "                    help='Weight decay (L2 loss on parameters).')\n",
        "parser.add_argument('--hidden', type=int, default=16,\n",
        "                    help='Number of hidden units.')\n",
        "parser.add_argument('--dropout', type=float, default=0.5,\n",
        "                    help='Dropout rate (1 - keep probability).')\n",
        "parser.add_argument('--way', type=int, default=5, help='way.')\n",
        "parser.add_argument('--shot', type=int, default=5, help='shot.')\n",
        "parser.add_argument('--qry', type=int, help='k shot for query set', default=1)\n",
        "parser.add_argument('--dataset', default='Amazon_eletronics')\n",
        "\n",
        "#args = parser.parse_args()\n",
        "args = parser.parse_known_args()[0]\n",
        "args.cuda = args.use_cuda and torch.cuda.is_available()\n",
        "\n",
        "random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "if args.cuda:\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "# Load data\n",
        "dataset = args.dataset\n",
        "adj, features, labels, degrees, class_list_train, class_list_valid, class_list_test, id_by_class = load_data(dataset)\n",
        "\n",
        "# Model and optimizer\n",
        "encoder = GPN_Encoder(nfeat=features.shape[1],\n",
        "            nhid=args.hidden,\n",
        "            dropout=args.dropout)\n",
        "\n",
        "optimizer_encoder = optim.Adam(encoder.parameters(),\n",
        "                       lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "\n",
        "if args.cuda:\n",
        "    encoder.cuda()\n",
        "    features = features.cuda()\n",
        "    adj = adj.cuda()\n",
        "    labels = labels.cuda()\n",
        "    degrees = degrees.cuda()\n",
        "\n",
        "def train(class_selected, id_support, id_query, n_way, k_shot):\n",
        "\n",
        "    encoder.train()\n",
        "\n",
        "    optimizer_encoder.zero_grad()\n",
        "\n",
        "    embeddings = encoder(features, adj)\n",
        "\n",
        "    z_dim = embeddings.size()[1]\n",
        "    support_embeddings = embeddings[id_support]\n",
        "    support_embeddings = support_embeddings.view([n_way, k_shot, z_dim])\n",
        "    query_embeddings = embeddings[id_query]\n",
        "\n",
        "    # compute loss\n",
        "    prototype_embeddings = support_embeddings.sum(1)\n",
        "\n",
        "    dists = cosine_dis(query_embeddings, prototype_embeddings)\n",
        "    output = F.log_softmax(-dists, dim=1)\n",
        "\n",
        "    labels_new = torch.LongTensor([class_selected.index(i) for i in labels[id_query]])\n",
        "    if args.cuda:\n",
        "        labels_new = labels_new.cuda()\n",
        "    loss_train = F.nll_loss(output, labels_new)\n",
        "\n",
        "    loss_train.backward()\n",
        "    optimizer_encoder.step()\n",
        "\n",
        "    if args.cuda:\n",
        "        output = output.cpu().detach()\n",
        "        labels_new = labels_new.cpu().detach()\n",
        "    acc_train = accuracy(output, labels_new)\n",
        "    f1_train = f1(output, labels_new)\n",
        "\n",
        "    return acc_train, f1_train\n",
        "\n",
        "\n",
        "def test(class_selected, id_support, id_query, n_way, k_shot):\n",
        "    encoder.eval()\n",
        "\n",
        "    embeddings = encoder(features, adj)\n",
        "    z_dim = embeddings.size()[1]\n",
        "\n",
        "    # embedding lookup\n",
        "    support_embeddings = embeddings[id_support]\n",
        "    support_embeddings = support_embeddings.view([n_way, k_shot, z_dim])\n",
        "    query_embeddings = embeddings[id_query]\n",
        "\n",
        "    # compute loss\n",
        "    prototype_embeddings = support_embeddings.sum(1)\n",
        "    dists = cosine_dis(query_embeddings, prototype_embeddings)\n",
        "    output = F.log_softmax(-dists, dim=1)\n",
        "\n",
        "    labels_new = torch.LongTensor([class_selected.index(i) for i in labels[id_query]])\n",
        "    if args.cuda:\n",
        "        labels_new = labels_new.cuda()\n",
        "    loss_test = F.nll_loss(output, labels_new)\n",
        "\n",
        "    if args.cuda:\n",
        "        output = output.cpu().detach()\n",
        "        labels_new = labels_new.cpu().detach()\n",
        "    acc_test = accuracy(output, labels_new)\n",
        "    f1_test = f1(output, labels_new)\n",
        "\n",
        "    return acc_test, f1_test\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    n_way = args.way\n",
        "    k_shot = args.shot\n",
        "    n_query = args.qry\n",
        "    meta_test_num = 50\n",
        "    meta_valid_num = 50\n",
        "\n",
        "    # Sampling a pool of tasks for validation/testing\n",
        "    valid_pool = [task_generator(id_by_class, class_list_valid, n_way, k_shot, n_query) for i in range(meta_valid_num)]\n",
        "    test_pool = [task_generator(id_by_class, class_list_test, n_way, k_shot, n_query) for i in range(meta_test_num)]\n",
        "\n",
        "    # Train model\n",
        "    t_total = time.time()\n",
        "    meta_train_acc = []\n",
        "\n",
        "    for episode in range(args.episodes):\n",
        "        id_support, id_query, class_selected = \\\n",
        "            task_generator(id_by_class, class_list_train, n_way, k_shot, n_query)\n",
        "\n",
        "        acc_train, f1_train = train(class_selected, id_support, id_query, n_way, k_shot)\n",
        "        meta_train_acc.append(acc_train)\n",
        "        if episode > 0 and episode % 10 == 0:    \n",
        "            print(\"-------Episode {}-------\".format(episode))\n",
        "            print(\"Meta-Train_Accuracy: {}\".format(np.array(meta_train_acc).mean(axis=0)))\n",
        "\n",
        "        # validation\n",
        "            meta_test_acc = []\n",
        "            meta_test_f1 = []\n",
        "            for idx in range(meta_valid_num):\n",
        "                id_support, id_query, class_selected = valid_pool[idx]\n",
        "                acc_test, f1_test = test(class_selected, id_support, id_query, n_way, k_shot)\n",
        "                meta_test_acc.append(acc_test)\n",
        "                meta_test_f1.append(f1_test)\n",
        "            print(\"Meta-valid_Accuracy: {}, Meta-valid_F1: {}\".format(np.array(meta_test_acc).mean(axis=0),\n",
        "                                                                        np.array(meta_test_f1).mean(axis=0)))\n",
        "            # testing\n",
        "            meta_test_acc = []\n",
        "            meta_test_f1 = []\n",
        "            for idx in range(meta_test_num):\n",
        "                id_support, id_query, class_selected = test_pool[idx]\n",
        "                acc_test, f1_test = test(class_selected, id_support, id_query, n_way, k_shot)\n",
        "                meta_test_acc.append(acc_test)\n",
        "                meta_test_f1.append(f1_test)\n",
        "            print(\"Meta-Test_Accuracy: {}, Meta-Test_F1: {}\".format(np.array(meta_test_acc).mean(axis=0),\n",
        "                                                                        np.array(meta_test_f1).mean(axis=0)))\n",
        "         \n",
        "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------Episode 10-------\n",
            "Meta-Train_Accuracy: 0.3090909090909091\n",
            "Meta-valid_Accuracy: 0.428, Meta-valid_F1: 0.30906666666666666\n",
            "Meta-Test_Accuracy: 0.396, Meta-Test_F1: 0.27679999999999993\n",
            "-------Episode 20-------\n",
            "Meta-Train_Accuracy: 0.3238095238095238\n",
            "Meta-valid_Accuracy: 0.428, Meta-valid_F1: 0.30373333333333336\n",
            "Meta-Test_Accuracy: 0.48800000000000004, Meta-Test_F1: 0.3702666666666667\n",
            "-------Episode 30-------\n",
            "Meta-Train_Accuracy: 0.38064516129032255\n",
            "Meta-valid_Accuracy: 0.46799999999999997, Meta-valid_F1: 0.3546666666666667\n",
            "Meta-Test_Accuracy: 0.45599999999999996, Meta-Test_F1: 0.34706666666666663\n",
            "-------Episode 40-------\n",
            "Meta-Train_Accuracy: 0.40487804878048783\n",
            "Meta-valid_Accuracy: 0.43200000000000005, Meta-valid_F1: 0.32013333333333327\n",
            "Meta-Test_Accuracy: 0.44, Meta-Test_F1: 0.3209333333333333\n",
            "-------Episode 50-------\n",
            "Meta-Train_Accuracy: 0.38431372549019605\n",
            "Meta-valid_Accuracy: 0.45599999999999996, Meta-valid_F1: 0.3377333333333333\n",
            "Meta-Test_Accuracy: 0.436, Meta-Test_F1: 0.32266666666666666\n",
            "-------Episode 60-------\n",
            "Meta-Train_Accuracy: 0.39672131147540984\n",
            "Meta-valid_Accuracy: 0.44799999999999995, Meta-valid_F1: 0.336\n",
            "Meta-Test_Accuracy: 0.44000000000000006, Meta-Test_F1: 0.3268\n",
            "-------Episode 70-------\n",
            "Meta-Train_Accuracy: 0.4084507042253522\n",
            "Meta-valid_Accuracy: 0.45199999999999996, Meta-valid_F1: 0.34093333333333325\n",
            "Meta-Test_Accuracy: 0.46799999999999997, Meta-Test_F1: 0.36106666666666665\n",
            "-------Episode 80-------\n",
            "Meta-Train_Accuracy: 0.42222222222222217\n",
            "Meta-valid_Accuracy: 0.444, Meta-valid_F1: 0.3342666666666666\n",
            "Meta-Test_Accuracy: 0.46799999999999997, Meta-Test_F1: 0.36373333333333335\n",
            "-------Episode 90-------\n",
            "Meta-Train_Accuracy: 0.4307692307692309\n",
            "Meta-valid_Accuracy: 0.46, Meta-valid_F1: 0.33906666666666657\n",
            "Meta-Test_Accuracy: 0.452, Meta-Test_F1: 0.3439999999999999\n",
            "-------Episode 100-------\n",
            "Meta-Train_Accuracy: 0.42970297029702975\n",
            "Meta-valid_Accuracy: 0.5000000000000001, Meta-valid_F1: 0.38773333333333326\n",
            "Meta-Test_Accuracy: 0.4640000000000001, Meta-Test_F1: 0.3529333333333333\n",
            "-------Episode 110-------\n",
            "Meta-Train_Accuracy: 0.436036036036036\n",
            "Meta-valid_Accuracy: 0.504, Meta-valid_F1: 0.3890666666666666\n",
            "Meta-Test_Accuracy: 0.48, Meta-Test_F1: 0.36706666666666654\n",
            "-------Episode 120-------\n",
            "Meta-Train_Accuracy: 0.43801652892561976\n",
            "Meta-valid_Accuracy: 0.4759999999999999, Meta-valid_F1: 0.35413333333333336\n",
            "Meta-Test_Accuracy: 0.45599999999999996, Meta-Test_F1: 0.3486666666666667\n",
            "-------Episode 130-------\n",
            "Meta-Train_Accuracy: 0.4396946564885496\n",
            "Meta-valid_Accuracy: 0.472, Meta-valid_F1: 0.3504\n",
            "Meta-Test_Accuracy: 0.43199999999999994, Meta-Test_F1: 0.33173333333333327\n",
            "-------Episode 140-------\n",
            "Meta-Train_Accuracy: 0.4439716312056738\n",
            "Meta-valid_Accuracy: 0.46799999999999997, Meta-valid_F1: 0.3441333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiU9I6T8d3xy"
      },
      "source": [
        "    embeddings = encoder(features, adj)\n",
        "    z_dim = embeddings.size()[1]\n",
        "    z_dim  \n",
        "    embeddings.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey5R7-MrfWEu"
      },
      "source": [
        "support_embeddings = embeddings[id_support]\n",
        "support_embeddings.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMOa2G89gkBI"
      },
      "source": [
        "support_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3_5Frqsfbme"
      },
      "source": [
        "support_embeddings = support_embeddings.view([n_way, k_shot, z_dim])\n",
        "support_embeddings.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyAQ1_z4grKV"
      },
      "source": [
        "support_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo83uFS3g150"
      },
      "source": [
        "query_embeddings = embeddings[id_query]\n",
        "query_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMTVLaTEjSRv"
      },
      "source": [
        "query_embeddings.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYMZwlLie_sD"
      },
      "source": [
        "\n",
        "    # compute loss\n",
        "prototype_embeddings = support_embeddings.sum(1)\n",
        "#تو هر سطری ستون هاشونو جمع میکنیم\n",
        "#هر سطری 5 تا سمپل توشه که متعلق به یک کلاسن"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huQcqigYi13x"
      },
      "source": [
        "prototype_embeddings.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6jXla2Fizu8"
      },
      "source": [
        "dists = euclidean_dist(query_embeddings, prototype_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOoUAM_-ejsD"
      },
      "source": [
        "   dists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGp1pWr3emvE"
      },
      "source": [
        "print(query_embeddings.shape,prototype_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}